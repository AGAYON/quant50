import logging
import os
from typing import Dict

from app.services import data, execute, features, model, optimize, report

# Configure logging
logger = logging.getLogger(__name__)


def run_pipeline() -> Dict[str, object]:
    """
    Executes the full quantitative pipeline.

    Returns
    -------
    Dict[str, object]
        Dictionary containing execution details and status.
    """
    logger.info("ðŸš€ Starting daily pipeline execution...")
    details = {}

    try:
        # 1. Load Data
        logger.info("Step 1: Loading data from DuckDB...")
        bars = data.get_all_bars()
        if bars.empty:
            logger.warning("âš ï¸ No data found in DuckDB. Skipping pipeline.")
            return {"error": "No data found"}
        details["bars_count"] = len(bars)

        # 2. Feature Engineering
        logger.info("Step 2: Generating features...")
        feats = features.generate_features(bars)
        if feats.empty:
            logger.warning("âš ï¸ No features generated.")
            return {"error": "No features generated"}
        details["features_shape"] = feats.shape

        # 3. Model Inference
        logger.info("Step 3: Loading model and predicting...")
        model_path = os.path.join("models", "latest_model.pkl")
        if not os.path.exists(model_path):
            logger.warning(f"âš ï¸ Model not found at {model_path}. Skipping inference.")
            return {"error": "Model not found"}

        model_bundle = model.load_model(model_path)
        scores = model.predict_scores(model_bundle, feats)

        # Get latest scores (for today/tomorrow)
        latest_date = scores["timestamp"].max()
        latest_scores = scores[scores["timestamp"] == latest_date].set_index("symbol")[
            "score"
        ]
        details["predictions_count"] = len(latest_scores)

        # 4. Optimization
        logger.info("Step 4: Optimizing portfolio...")
        # Need covariance matrix for optimization
        # We'll use the last N days of returns from bars
        pivot_prices = bars.pivot(index="timestamp", columns="symbol", values="close")
        returns = pivot_prices.pct_change().tail(252)  # Last year
        cov_matrix = optimize.compute_ledoit_wolf_cov(returns)

        # Align covariance with scores
        # Note: optimize_weights handles alignment internally but
        # expects matching indices roughly
        # We'll pass the full covariance and let it select

        # Get previous weights if available (for turnover)
        current_positions = execute.get_current_positions()
        prev_weights = None
        if not current_positions.empty:
            account = execute.get_account()
            equity = float(account.get("equity", 0) or 0)
            if equity > 0:
                current_positions["weight"] = (
                    current_positions["qty"] * current_positions["current_price"]
                ) / equity
                prev_weights = current_positions.set_index("symbol")["weight"]

        opt_result = optimize.optimize_weights(
            expected_returns=latest_scores,
            cov_matrix=cov_matrix,
            prev_weights=prev_weights,
            config=optimize.OptimizeConfig(max_assets=50),
        )
        target_weights = opt_result["weights"]
        details["target_weights_count"] = len(target_weights)

        # 5. Execution
        logger.info("Step 5: Executing orders...")
        exec_result = execute.rebalance_portfolio(target_weights)
        details["execution"] = exec_result

        # 6. Reporting
        logger.info("Step 6: Generating report...")
        rep = report.generate_daily_report()
        pdf_path = report.create_pdf_report(rep)
        details["report_path"] = pdf_path

        logger.info("âœ… Pipeline completed successfully.")
        return details

    except Exception as e:
        logger.error(f"âŒ Pipeline failed: {e}", exc_info=True)
        return {"error": str(e)}


def run_training_pipeline(dry_run: bool = False) -> Dict[str, object]:
    """
    Executes the weekly training pipeline.

    Parameters
    ----------
    dry_run : bool
        If True, does not save artifacts.

    Returns
    -------
    Dict[str, object]
        Dictionary containing training details and status.
    """
    # This will be implemented fully when we touch weekly_train.py
    # For now, we can move the logic from weekly_train.py here or just keep it there
    # The plan said "Add run_training_pipeline for weekly training"
    # I will implement it based on what I saw in jobs/weekly_train.py

    # Actually, let's keep it simple for now and just focus on daily run refactor first
    # But the plan says "Add run_training_pipeline", so I should probably
    # add a placeholder or move logic
    pass
